\documentclass[11pt,a4paper,ngerman]{scrartcl}
 
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[ngerman]{babel}
\usepackage{amsmath} 
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{framed}

\usepackage{glossaries}
\title{Anmerkungen zum Paper}
\author{Horst Schneider}
\date{\today{}}

\newglossaryentry{geo-replicated}
{
  name=geo-replicated,
  description={bezeichnet die räumlich voneinander getrennte Verteilung von replizierten (nicht-relationalen) Datenbanken}
}

\newglossaryentry{eventual consistency}
{
  name=eventual consistency,
  description={bezeichnet die Einschränkung, dass Daten nach dem CAP Theorem zwar sofort verfügbar und partition tolerant sind, dafür aber nicht sofort konsistent sind, sondern erst an einem unbestimmten Punkt in der Zukunft}
}

\newglossaryentry{quiescent consistency}
{
  name=quiescent consistency,
  description={basiert auf den zwei Prinzipen "Method calls should appear to happen in a one-at-a-time, sequential order" und "Method calls separated by a period of quiescence should appear
to take effect in their real-time order". Ein Method Call ist definiert als die Sequenz \textit{invocation}, \textit{pending} und \textit{response}. Prinzip 1 besagt, dass gleichzeitige invocations, die die gleichen Werte manipulieren, selbst bei überlappender pending Phasen keine Mischung ihrer Ergebnisse erzeugen sollten. Man weiß zwar nicht, welcher Call zuerst abgeschlossen ist, aber die Ergebnisse sollten trotzdem aussehen, als ob eine sequentielle Reihenfolge der Befehle gegeben wäre. Prinzip zwei besagt, dass, wenn es eine \textit{ruhende} Phase (= keine pending Calls) zwischen zwei Method Calls gab, die Ergebnisse der beiden Method Calls in ihrer real-time order vorhanden sein sollten. Bsp.: \glqq For example, suppose A and B concurrently enqueue x and y in a FIFO queue. The queue becomes quiescent, and then C enqueues z. We may not be able to predict the relative order of x and y in the queue, but we know they are ahead of z.\grqq}
}


\makeglossaries

\begin{document}
 
\maketitle 
\pagebreak
\tableofcontents
\section{Abstract}
\begin{itemize}
\item \Gls{geo-replicated} Datenbanken garantieren sofortige Verfügbarkeit und Partitionstoleranz auf Kosten schwacher Konsistenz -> \gls{eventual consistency}
\item es gibt einige Verwirrung über die Semantik von \gls{eventual consistency}
\item die Vergleichbarkeit verschiedener Semantiken von \gls{eventual consistency} ist unmöglich, da die Semantik oft nur implizit durch die Implementierung gegeben ist bzw. keine Formalismen bei der Beschreibung verwendet werden
\item \gls{eventual consistency} ist verbunden mit verschiedenen Features wie conflict resolution policies, session guarantees, casuality guarantees und Konsistenzleveln
\end{itemize}

\begin{framed}
Ziel des papers ist es, ein Framework zur deklarativen Spezifikation von \gls{eventual consistency} zu bieten, das auf Axiomen basiert.
\end{framed}

\section{Introduction}
\begin{itemize}
\item Moderne Internetanwendungen basieren auf verteilten Datenbanksystemen, die oft \gls{geo-replicated} sind
\begin{itemize}
\item \gls{geo-replicated} Datenbanken erfordern \textbf{partition tolerance}
\item die Anwender fordern \textbf{sofortige Verfügbarkeit}
\item -> nach dem CAP-Theorem kann daher keine starke Konsistenz gewährleistet werden
\end{itemize}
\item \gls{eventual consistency} beschreibt die \textbf{Garantie}, dass die Datenbank irgendwann in einen konsistenten Zustand kommt, wenn keine Updates mehr die Datenbank erreichen
\item Im Gegensatz zu relationalen Datenbanken sind die Konsistenzmodelle von \gls{geo-replicated} Datenbanken nicht eindeutig und ausreichend studiert
\item Der Ausruck \gls{eventual consistency} ist nicht eindeutig besetzt und wird als catch-all buzzword verwendet
\item Spezifizierungen von \gls{geo-replicated} Konsistenzmodellen sind aus verschiedenen Gründen unzureichend:
\begin{itemize}
\item verschiedene, unvereinbare Formalismen bzw. keine Formalismen, oft an spezifische Implementierungen gebunden
\item schwache Garantien; \gls{eventual consistency} bezeichnet oft nur \gls{quiescent consistency}, einem theoretischen Ansatz, der nicht den praktischen Fall berücksichtigt, dass eventuell nie der Zustand eintritt, in dem keine neuen Updates an der Datenbank ankommen
\item Schwierigkeit von Conflict Resolution Policies: Vorgehen, wenn zwei Replicas beim Synchronisieren unterschiedliche Versionen des gleichen Objektes besitzen
\item Kombination verschiedener Konsistenzlevel: manche Systeme bieten die Mischung von \gls{eventual consistency} und strong consistency (z.B. Amazon dynamoDB). Ebenso gibt es Implementierungen für Transaktionen in \gls{geo-replicated} Systemen. Die Semantik hinter verschiedenen Konsistenzleveln und deren Zusammenspiel ist schwierig zu erfassen.
\end{itemize}
\item ein einheitlicher Formalismus soll die Beantwortung folgender Fragestellungen erleichtern:
\begin{itemize}
\item Erfüllen die Anforderungen an meine Anwendung die gewünschte Ausprägung von \gls{eventual consistency}?
\item Kann ich einen replizierten Datentyp aus System X in System Y verwenden?
\item Welche Semantik steckt hinter der Kombination verschiedener Formen von \gls{eventual consistency}?
\end{itemize}
\item Die Spezifikation eines \gls{eventual consistency} models besteht aus folgenden Komponenten:
\begin{itemize}
\item Spezifikation verschiedener Datentypen (Register, Zähler, multi-value Register (in [17]: binary blobs mit key) observed-remove sets) und deren conflict resolution policy auf Objektebene
\item Spezifikation der Datenbankweiten Konsistenzgarantien anhand von Axiomen
\item Interface-Spezifikation: gibt den Anwendern die Möglichkeit, Konsistenzlevel für Operationen, gebündelte Operationen (fences) und Transaktionen festzulegen (bspw. mit Annontationen) 
\end{itemize}
\item verschiedene exisitierende Formen von \gls{eventual consistency} werden systematisch in ein Spezifikationsframework überführt, das Garantien und Features der verschiedenen Technologien einheitlich ausdrücken kann und so Vergleichbarkeit schafft bzw. Interaktionen zwischen Systemen beschreiben kann
\item die Spezifikation wird durch eine abstrakte Implementierung, basierend auf Algorithmen in existierenden Systemen, validiert
\item die Spezifikation soll stärker als \gls{quiescent consistency} sein und auch in dem Fall zutreffen, wenn kontinuierlich Updates an der Datenbank ankommen
\item Das Paper beinhaltet Beweise, dass die Spezifikation die rigorose Vergleichbarkeit zwischen Features und Garantien gewährleistet
\end{itemize}

\section{Replicated Data Types}
Grundideen:

\begin{itemize}
\item Replizierte Datenbank speichert Objekte aus der Menge $Obj = \lbrace x,y,...\rbrace$
\item Jedes Objekt besitzt einen Wert aus dem Set $Val$
\item Jedes Objekt $x \in Obj$ besitzt einen Typ type($x$) $\in Type$, der die Menge $Op_{type(x)}$ von Operationen festlegt, die Clients auf dem Objekt ausführen können
\item Beispiele:
\begin{itemize}
\item Datentyp Counter mit den Operationen \textit{read} und \textit{increment}: $Op_{ctr} = \lbrace rd,inc\rbrace$
\item Datentyp Integer-Register mit den Operationen \textit{read} und \textit{write}: $Op_{ctr} = \lbrace \text{rd}\rbrace \cup \lbrace \text{wr}(k) | k \in \mathbb{Z}$
\end{itemize}
\item Die Semantik von sequenziell ausgeführten Operationen eines Datentyps $\tau$ in einem strongly consistent System kann mit folgender Funktion ausgedrückt werden: $S_{\tau} : Op_{\tau}^+ \rightarrow Val$
\item $\sigma$ beschreibt eine Sequenz beliebiger Operationen
\item $\perp$ beschreibt Operationen, die keinen Wert zurückgeben
\item Beispiele:
\begin{align} 
S_{ctr}(\sigma \text{ rd}) &= \text{(the number of inc operations in $\sigma$);} \\
S_{intreg}(\sigma \text{ rd})) &= k; \text{if wr(0) $\sigma$ = $\sigma_1$ wr($k$) $\sigma_2$ and $\sigma_2$ does not contain wr operations;} \\
S_{ctr}(\sigma \text{ wr($k$)}) &= S_{intreg}(\sigma \text{ inc}) = \perp 
\end{align}

\end{itemize}

\section{Zitate für die Einleitung}
http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/APISummary.html

"Eventually Consistent Reads

When you read data (GetItem, BatchGetItem, Query or Scan operations), the response might not reflect the results of a recently completed write operation (PutItem, UpdateItem or DeleteItem). The response might include some stale data. Consistency across all copies of the data is usually reached within a second; so if you repeat your read request after a short time, the response returns the latest data. "

------

http://blog.mongodb.org/post/498145601/on-distributed-consistency-part-2-some-eventual

MongoDB docs

This sort of system we term “single writer eventual consistency”.  So what are its properties?  (1) A client could read stale data. (2) The client could see out-of-order write operations. (...) So this is our weakest form of consistency - eventually consistent with out of order reads in the short term. 
 

\pagebreak
\printglossaries

\end{document}
